gym_qco/routing-layer-chalmers-6-v0:
  n_timesteps: !!float 1e6
  policy: 'MlpPolicy'
  # policy: 'MultiInputPolicy'
  callback:
  # - gym_qco.envs.routing_layer.callbacks.LogQValues
  - sb3_contrib.common.callbacks.EveryEpisodeEnd:
      callback: gym_qco.envs.routing_layer.callbacks.OnCircuitRouted
  eval_callback: 
    gym_qco.envs.routing_layer.callbacks.RoutingEvaluation:
      callback_after_eval:
        stable_baselines3.common.callbacks.StopTrainingOnNoModelImprovement:
          max_no_improvement_evals: 3
          min_evals: 5
  batch_size: 512
  gradient_steps: -1


gym_qco/routing-layer-chalmers-9-v0:
  n_timesteps: !!float 1e6
  # policy: 'MlpPolicy'
  policy: 'MultiInputPolicy'
  # callback:
  # - gym_qco.envs.routing_layer.callbacks.LogQValues
  # - sb3_contrib.common.callbacks.EveryEpisodeEnd:
  #     callback: gym_qco.envs.routing_layer.callbacks.OnCircuitRouted
  # eval_callback: 
  #   gym_qco.envs.routing_layer.callbacks.RoutingEvaluation
  batch_size: 512
  gradient_steps: -1
